{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16179,
     "status": "ok",
     "timestamp": 1589387836451,
     "user": {
      "displayName": "Ксения Дмитриева",
      "photoUrl": "",
      "userId": "12056694818885940877"
     },
     "user_tz": -180
    },
    "id": "KpbXQMVPkiDi",
    "outputId": "fba0a157-7b74-4b00-a7db-3ff278bdd5af"
   },
   "outputs": [],
   "source": [
    "# Uncomment to install albumentations\n",
    "#!pip install -U git+https://github.com/albu/albumentations --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mbkj9JOJshQH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "from argparse import ArgumentParser\n",
    "import albumentations as albu\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import tqdm\n",
    "from torch.nn import functional as fnn\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "\n",
    "from hack_utils import NUM_PTS, CROP_SIZE\n",
    "from hack_utils import ScaleMinSideToSize, CropCenter, TransformByKeys\n",
    "from hack_utils import ThousandLandmarksDataset\n",
    "from hack_utils import restore_landmarks_batch, create_submission\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fjk2TBHpsw_v"
   },
   "outputs": [],
   "source": [
    "def train(model, loader, loss_fn, optimizer, device):\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    for batch in tqdm.tqdm(loader, total=len(loader), desc=\"training...\"):\n",
    "        images = batch[\"image\"].to(device)  # B x 3 x CROP_SIZE x CROP_SIZE\n",
    "        landmarks = batch[\"landmarks\"]  # B x (2 * NUM_PTS)\n",
    "\n",
    "        pred_landmarks = model(images).cpu()  # B x (2 * NUM_PTS)\n",
    "        loss = loss_fn(pred_landmarks, landmarks, reduction=\"mean\")\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return np.mean(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lRJYv1I5sxC3"
   },
   "outputs": [],
   "source": [
    "def validate(model, loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    for batch in tqdm.tqdm(loader, total=len(loader), desc=\"validation...\"):\n",
    "        images = batch[\"image\"].to(device)\n",
    "        landmarks = batch[\"landmarks\"]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_landmarks = model(images).cpu()\n",
    "        loss = loss_fn(pred_landmarks, landmarks, reduction=\"mean\")\n",
    "        val_loss.append(loss.item())\n",
    "\n",
    "    return np.mean(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EgD2L_GLsxLl"
   },
   "outputs": [],
   "source": [
    "def predict(model, loader, device):\n",
    "    model.eval()\n",
    "    predictions = np.zeros((len(loader.dataset), NUM_PTS, 2))\n",
    "    for i, batch in enumerate(tqdm.tqdm(loader, total=len(loader), desc=\"test prediction...\")):\n",
    "        images = batch[\"image\"].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_landmarks = model(images).cpu()\n",
    "        pred_landmarks = pred_landmarks.numpy().reshape((len(pred_landmarks), NUM_PTS, 2))  # B x NUM_PTS x 2\n",
    "\n",
    "        fs = batch[\"scale_coef\"].numpy()  # B\n",
    "        margins_x = batch[\"crop_margin_x\"].numpy()  # B\n",
    "        margins_y = batch[\"crop_margin_y\"].numpy()  # B\n",
    "        prediction = restore_landmarks_batch(pred_landmarks, fs, margins_x, margins_y)  # B x NUM_PTS x 2\n",
    "        predictions[i * loader.batch_size: (i + 1) * loader.batch_size] = prediction\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u8YYvZW2x98k"
   },
   "outputs": [],
   "source": [
    "NAME = \"resneXt50_bs848_epochs24\"\n",
    "DATA = \"data\"\n",
    "BATCH_SIZE = 848\n",
    "EPOCHS = 24\n",
    "LEARNING_RATE = 1e-3\n",
    "GPU = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 695746,
     "status": "ok",
     "timestamp": 1589394229660,
     "user": {
      "displayName": "Ксения Дмитриева",
      "photoUrl": "",
      "userId": "12056694818885940877"
     },
     "user_tz": -180
    },
    "id": "5NYt5uPftP7o",
    "outputId": "1db86019-f031-41b7-f203-4350cddf814a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "Cook train data from csv...\n",
      "Chunk... 0... 1... 2... 3... 4... 5... 6... 7... Finish\n",
      "Convert to tensor... Implementing transforms...\n",
      "Applying augmentations...\n",
      "Finish\n",
      "Cook val data from csv...\n",
      "Chunk... 0... 1... 2... 3... 4... 5... 6... 7... Finish\n",
      "Convert to tensor... Implementing transforms...\n",
      "Finish\n"
     ]
    }
   ],
   "source": [
    "# 1. prepare data & models\n",
    "train_transforms = transforms.Compose([\n",
    "    ScaleMinSideToSize((CROP_SIZE, CROP_SIZE)),\n",
    "    CropCenter(CROP_SIZE),\n",
    "    TransformByKeys(transforms.ToPILImage(), (\"image\",)),     \n",
    "    TransformByKeys(transforms.ToTensor(), (\"image\",)),\n",
    "    TransformByKeys(transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), (\"image\",)),\n",
    "])\n",
    "    \n",
    "val_transforms = transforms.Compose([\n",
    "    ScaleMinSideToSize((CROP_SIZE, CROP_SIZE)),\n",
    "    CropCenter(CROP_SIZE),\n",
    "    TransformByKeys(transforms.ToPILImage(), (\"image\",)),     \n",
    "    TransformByKeys(transforms.ToTensor(), (\"image\",)),\n",
    "    TransformByKeys(transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), (\"image\",)),\n",
    "])\n",
    "\n",
    "albumentations = [#albu.ShiftScaleRotate(),\n",
    "#                    albu.IAAPerspective(),\n",
    "                    albu.HueSaturationValue(p=0.3),\n",
    "#                    albu.RandomBrightnessContrast(),\n",
    "#                    albu.GaussNoise(p=0.3),\n",
    "#                    albu.GaussianBlur(p=0.1),\n",
    "                    albu.Blur(p=0.1),\n",
    "                    albu.ChannelShuffle(p=0.2)\n",
    "#                    albu.CLAHE()\n",
    "                      ]\n",
    "\n",
    "print(\"Reading data...\")\n",
    "train_dataset = ThousandLandmarksDataset(os.path.join(DATA, 'train'), train_transforms, albumentations, split=\"train\")\n",
    "train_dataloader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers=4, pin_memory=True,\n",
    "                                    shuffle=True, drop_last=True)\n",
    "val_dataset = ThousandLandmarksDataset(os.path.join(DATA, 'train'), val_transforms, split=\"val\")\n",
    "val_dataloader = data.DataLoader(val_dataset, batch_size=BATCH_SIZE, num_workers=4, pin_memory=True,\n",
    "                                    shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fW6XDXeSlP6S"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3224,
     "status": "ok",
     "timestamp": 1589394259954,
     "user": {
      "displayName": "Ксения Дмитриева",
      "photoUrl": "",
      "userId": "12056694818885940877"
     },
     "user_tz": -180
    },
    "id": "AfZeGkPmy_e7",
    "outputId": "72159193-a75c-4082-ba3f-acae4fb5fefc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model...\n",
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth\" to C:\\Users\\svizo/.cache\\torch\\checkpoints\\resnext50_32x4d-7cdf4587.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9db6358313b439586e1b06727ac8dd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=100441675), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating model...\")\n",
    "device = torch.device(\"cuda: 0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)\n",
    "model = models.resnext50_32x4d(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 2 * NUM_PTS, bias=True)\n",
    "#   model.load_state_dict(torch.load('resneXt50_bs848_epochs6_best.pth', map_location='cpu'))\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f'Using {torch.cuda.device_count()} gpus')\n",
    "    model = nn.DataParallel(model)\n",
    "        \n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, amsgrad=True)\n",
    "#   optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, amsgrad=False)\n",
    "#   optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9, nesterov=True) #, weight_decay=0.0005)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, factor=0.1)\n",
    "loss_fn = fnn.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GB6LgjnNWcBk"
   },
   "outputs": [],
   "source": [
    "# Freeze some layers\n",
    "for param in model.conv1.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.bn1.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.relu.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.maxpool.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.layer1.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for i in range(2):\n",
    "    for param in model.layer2[i].parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 578,
     "status": "ok",
     "timestamp": 1589394468270,
     "user": {
      "displayName": "Ксения Дмитриева",
      "photoUrl": "",
      "userId": "12056694818885940877"
     },
     "user_tz": -180
    },
    "id": "yZEDIIcOlCZn",
    "outputId": "1b1f4f82-7351-45fd-bb7f-0f99cd03a4f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26111894"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check number of parameters to train\n",
    "model_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "model_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 531
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 45234,
     "status": "error",
     "timestamp": 1589394514841,
     "user": {
      "displayName": "Ксения Дмитриева",
      "photoUrl": "",
      "userId": "12056694818885940877"
     },
     "user_tz": -180
    },
    "id": "WwA97TsktP-c",
    "outputId": "aa6723e4-88c2-40c1-c949-10683e11b353"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "training...:   0%|          | 0/371 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready for training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "training...:   0%|          | 1/371 [00:12<1:19:04, 12.82s/it]\u001b[A\n",
      "training...:   1%|          | 2/371 [00:16<1:02:02, 10.09s/it]\u001b[A\n",
      "training...:   1%|          | 3/371 [00:21<51:35,  8.41s/it]  \u001b[A\n",
      "training...:   1%|          | 4/371 [00:25<44:27,  7.27s/it]\u001b[A\n",
      "training...:   1%|▏         | 5/371 [00:30<39:17,  6.44s/it]\u001b[A\n",
      "training...:   2%|▏         | 6/371 [00:34<35:41,  5.87s/it]\u001b[A\n",
      "training...:   2%|▏         | 7/371 [00:39<33:09,  5.47s/it]\u001b[A\n",
      "training...:   2%|▏         | 8/371 [00:43<31:23,  5.19s/it]\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-36ae81f3c0b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbest_val_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-c16bc5dc5a82>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loader, loss_fn, optimizer, device)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# B x 3 x CROP_SIZE x CROP_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mlandmarks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"landmarks\"\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# B x (2 * NUM_PTS)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 2. train & validate\n",
    "print(\"Ready for training...\")\n",
    "best_val_loss = np.inf\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train(model, train_dataloader, loss_fn, optimizer, device=device)\n",
    "    val_loss = validate(model, val_dataloader, loss_fn, device=device)\n",
    "    scheduler.step(val_loss)\n",
    "    print(\"Epoch #{:2}:\\ttrain loss: {:5.3}\\tval loss: {:5.3}\".format(epoch, train_loss, val_loss))\n",
    "    print(f'lr = {optimizer.param_groups[0][\"lr\"]}')\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        with open(f\"{NAME}_best.pth\", \"wb\") as fp:\n",
    "            torch.save(model.state_dict(), fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14222,
     "status": "error",
     "timestamp": 1589394536462,
     "user": {
      "displayName": "Ксения Дмитриева",
      "photoUrl": "",
      "userId": "12056694818885940877"
     },
     "user_tz": -180
    },
    "id": "I5g_GIP2WOpm",
    "outputId": "fb9d7655-ad56-4186-b034-89d2c97f4b9b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "training...:   0%|          | 0/371 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once again ready for training...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-0c363dafca63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-c16bc5dc5a82>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loader, loss_fn, optimizer, device)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    108\u001b[0m                     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                     \u001b[0;31m# Use the max. for normalizing running avg. of gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 2.5. More train & validate \n",
    "print(\"Once again ready for training...\")\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 1e-4\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, amsgrad=True)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, factor=0.5)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train(model, train_dataloader, loss_fn, optimizer, device=device)\n",
    "    val_loss = validate(model, val_dataloader, loss_fn, device=device)\n",
    "    scheduler.step(val_loss)\n",
    "    print(\"Epoch #{:2}:\\ttrain loss: {:5.3}\\tval loss: {:5.3}\".format(epoch, train_loss, val_loss))\n",
    "    print(f'lr = {optimizer.param_groups[0][\"lr\"]}')\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        with open(f\"{NAME}_best.pth\", \"wb\") as fp:\n",
    "            torch.save(model.state_dict(), fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 792,
     "status": "ok",
     "timestamp": 1589111256573,
     "user": {
      "displayName": "Timur Kamaliev",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjwEUOo_ezCPA45ktj6hnI4JhxHVDAVHNRTmPxGXA=s64",
      "userId": "12270392991844786490"
     },
     "user_tz": -180
    },
    "id": "vaBjb6_ISl-k",
    "outputId": "3da1e0f4-e603-4919-9726-d043d0fa2f18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7404832643212624"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 997,
     "status": "error",
     "timestamp": 1589394589698,
     "user": {
      "displayName": "Ксения Дмитриева",
      "photoUrl": "",
      "userId": "12056694818885940877"
     },
     "user_tz": -180
    },
    "id": "1R8Shh8azPXU",
    "outputId": "86ce19f4-80d2-4da1-d071-dd9933fc9e57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cook test data from csv...\n",
      "Chunk... 0... 1... Finish\n",
      "Convert to tensor... Implementing transforms...\n",
      "Finish\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-8c96dad5d604>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                                   shuffle=False, drop_last=False)\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{NAME}_best.pth\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mbest_state_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_state_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'resneXt50_bs848_epochs24_best.pth'"
     ]
    }
   ],
   "source": [
    "    # 3. predict\n",
    "    test_dataset = ThousandLandmarksDataset(os.path.join(DATA, 'test'), val_transforms, split=\"test\")\n",
    "    test_dataloader = data.DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=4, pin_memory=True,\n",
    "                                      shuffle=False, drop_last=False)\n",
    "\n",
    "    with open(f\"{NAME}_best.pth\", \"rb\") as fp:\n",
    "        best_state_dict = torch.load(fp, map_location=\"cpu\")\n",
    "        model.load_state_dict(best_state_dict)\n",
    "\n",
    "    test_predictions = predict(model, test_dataloader, device)\n",
    "    with open(f\"{NAME}_test_predictions.pkl\", \"wb\") as fp:\n",
    "        pickle.dump({\"image_names\": test_dataset.image_names,\n",
    "                     \"landmarks\": test_predictions}, fp)\n",
    "\n",
    "    create_submission(DATA, test_predictions, f\"{NAME}_submit.csv\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "train.ipynb",
   "provenance": [
    {
     "file_id": "10vehBOJCY8CC-MMe2rdZEC_FUdoFwgvo",
     "timestamp": 1588419967217
    },
    {
     "file_id": "16Ya_5bNVKJOlDhu_lwczT1yRPl-HCzy3",
     "timestamp": 1588401121458
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
