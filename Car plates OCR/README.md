## Описание
В качестве бейзлайна использовал блокнот, подготовленный [Алексеем Ярошенко](https://github.com/alexyar88).

## Подготовка данных
Почистил исходный датасет: избавился от символов кириллицы и устранил ошибки в номерах в файле `train.json`.

## Детекция/сегментация
Оставил без изменений предложенные архитектуры `FastRCNN` и `MaskRCNN`. Обучал одну эпоху на всем датасете без валидации при `batch_size=4`. Аугментаций не использовал. Предсказания строил при разных значениях порога `threshold`.

## Распознавание
В качестве `FeatureExtractor` пробовал использовать `resnet18, resnet34, resneXt50`. В `SequencePredictor` пробовал менять `GRU` на `bidirectional LSTM`, размер и число скрытых слоев. Из аугментаций использовал стандартную нормализацию и самописный Blur. 

В итоге, обучал, в среднем, 4-5 эпох при `batch_size=64`, валидировался на 10% данных. Оптимизатор - `AdamW`. Целевую метрику оставил без изменений - `CTC`.

## Файл решения
При формировании файла решения применял следующую эвристику: первоначально строил предсказания детектора при `threshold=0.97`. При этом оставались недетектированными и нераспознанными порядка 40-60 примеров из тестового набора. Затем последовательно понижал величину `threshold` до 0.93 и 0.74, вновь прогонял пайплайн, из сформированного файла решения вытаскивал недостающие позиции и добавлял их в исходный сабмит. Таким образом, удалось сократить число необработанных примеров до 6-7. 

## Итоги
На паблике удалось последовательно улучшить скор, но на привате ситуация оказалось не такой радужной. Проанализировал все свои посылки: в итоге, лучший финальный скор показал исходный блокнот при минимальных изменениях на очищенных данных (1.41 на private).

На что стоило обратить большее внимание:
- детектор - попробовать другие модели, использовать большее число эпох обучения с валидацией;
- реализовать побольше различных аугментаций (в частности, на детекторе);
- поэкспериментировать с размером изображений на входе;
- попробовать другие варианты лосса.
